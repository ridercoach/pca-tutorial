---
title: "Principal Component Analysis: A Simple Example"
author: "Eric N. Moyer"
date: "`r Sys.Date()`"
output:
  tufte::tufte_handout:
    citation_package: natbib
    latex_engine: pdflatex
  tufte::tufte_html: default
  tufte::tufte_book:
    citation_package: natbib
    latex_engine: pdflatex
bibliography: skeleton.bib
link-citations: yes
---

```{r setup, include=FALSE}
library(tufte)
library(tidyverse)
library(ggbiplot)
# invalidate cache when the tufte version changes
knitr::opts_chunk$set(tidy = FALSE, cache.extra = packageVersion('tufte'))
options(htmltools.dir.version = FALSE)
source("pca-utilities.R")
```

# Introduction

This exploration is inspired by Luke Hayden's excellent tutorial on DataCamp
about doing Principal Component Analysis in R.^[
[Link](https://www.datacamp.com/community/tutorials/pca-analysis-r) to the
article]  I use the same data and take the same basic approach, but Mr. Hayden
explores more of the capabilities of `ggbiplot()`, and I take a closer look at
the information returned by `prcomp()`.

# The Data

We will use the `mtcars` dataset built into R, but we will drop 
the two categorical features (eighth and ninth columns):

```{r data}
data <- mtcars[c(1:7, 10, 11)]
knitr::kable(
  data[1:4,], caption = 'The first few rows of the data'
)
```

Often in data analysis it is helpful to put all of our features "on the same
footing" by *centering* (subtracting the mean) and *scaling* the values (so that
they have unit variance) of each one, as shown below.^[This can be done for you by
`prcomp()`, but for illustrative reasons I am doing it separately.] The mathematical 
reasons for doing this are better explained by others^[such as this link], but you 
should understand that even though the numbers have changed, the patterns in the 
data are preserved.

```{r scaled_data}
scaled_data <- scale(data, center = TRUE, scale = TRUE)
knitr::kable(
  format(scaled_data[1:4,], digits = 1), 
  caption = 'Same data, centered and scaled'
)
```

# The Data as a Vector Space

Our data has nine features.  For any given "observation" (e.g., Mazda RX4), the
feature values can be thought of as the coordinates of a point (or the
components of a vector, which is essentially the same thing) in nine-dimensional
space, which is described by a coordinate system having nine axes. We have these
axes because they correspond to real-world quantities that we can measure.
However, this real-world coordinate system is not necessarily the best one for
seeing important patterns in the data.

Principal Component Analysis transforms our data onto a new set of
axes^[resources, including 3blue1brown...], as shown below. *The observations 
have not changed*; they are simply being described in terms of a different 
coordinate system, in which the axes are the "principal components" found in 
the data (PC1, PC2, etc) instead of the original measured quantities (mpg, 
cyl, etc.)

```{r xformed_data}
pca <- prcomp(scaled_data)
knitr::kable(
  format(pca$x[1:4,], digits = 1), 
  caption = 'Same data, transformed by PCA'
)
```

The principal components (PCs) are really a new set of features (though not
real-world features) that correspond to what matters most in our data.  Not only
can this provide insight, but it often happens that most of the important
information in the data is described by just a few of the PCs, allowing us to
discard the others without losing much.  Fewer features (especially if you are
starting with hundreds) makes everything downstream a little simpler.

However, there is a downside: it can often be challenging to relate the PCs to
real-world quantities that we can control in order to gain some practical
benefit (which is usually the ultimate goal of any data project.)

# Simple Model for Evaluating PCA Effects

It is not the purpose of this article to do any modeling or prediction, nor 
is PCA itself concerned at all with inputs, outputs, or predictions.^[PCA views 
all features the same, and simply detects interactions between them.] 
However, PCA is almost always used as just one tool in a project that *does* 
do some kind of modeling, so it will be helpful to have a simple model to 
use here to evaluate the effects of PCA.

We will just do a basic linear regression, predicting mpg from all the other
features, and evaluating the performance of the model by taking the square root
of the sum of the squares of the residuals, which are included in the data
structure returned by `lm()`.  We use the data that has been centered and
scaled, because that is what is used to determine the PCs:

```{r model_init}
mod_scaled_data <- lm(mpg ~ ., as.data.frame(scaled_data))
sqrt(sum(mod_scaled_data$residuals^2))
```

The above number is the composite, across all the observations in the data set, 
of the difference between the prediction of the model and the actual value.  A 
lower value indicates a better-performing model.  This value comes from using the 
complete set of original features, and represents the best we can do without PCA. As we proceed, we will rerun this test in various ways based on insight gained from PCA, and 
see what happens.

# Correlation in the Data

Nothing we do in this exploration assumes any of the features of our data 
to be either "inputs" or "outputs".  We are not doing any modeling (not 
really) or prediction; we just have a table that records the values of several 
attributes for a bunch of samples.

And yet, in the real world, which is where our data comes from, there 
*does* exist correlation (the identification of which is often a %>%  first step 
toward understanding how things work, which is what we really want.)  In this 
example, which uses a small dataset of features that are familiar to most 
of us, much of the correlation is intuitive and we will see it in the 
PCA results.  However, if we were dealing with hundreds of features rather 
than nine, and those features were more abstract than physical quantities 
such as weight and engine displacement, this might not be the case.

# Calling `prcomp()`

Performing a basic PCA in R is very easy, as shown below.  You can use the 
`center` argument to shift the feature values so that they have zero means, and 
the `scale` argument to scale the feature values to have unit variance, both 
of which are generally good things to do.

```{r prcomp}
pca = prcomp(data, center = TRUE, scale = TRUE)
# prettify what we would get from summary(pca)
m <- format(summary(pca)$importance, digits = 1)
knitr::kable(
  as.data.frame(m), caption = 'PCA Summary.'
)
```

We had nine original features, and we got nine principal components, and 
PCA gives them to us in order of decreasing importance.  The most interesting 
thing in the table above is the "Proportion of Variance" row: the most important 
principal component (PC1) captures (or, you might say, controls) %63 of what is 
"happening" in our data.  Together, the first two principal components explain 
86% of the variance.  In general, if we can figure out how the most important 
principal comonents relate to real-world quantities that we can measure and 
control, then we know what to focus on in order to bring about the changes 
we desire in the world represented by our data.

Much of this article is devoted to interpreting our PCA results; however, 
first I want to look more closely at the information returned by `prcomp()`

# Data returned by `prcomp()`: `sdev`, `rotation`

```{r prcomp_results}
names(pca)
```

The data  structure returned by `prcomp()` has five elements with the names 
shown above. The `sdev` element is a vector of the standard deviations of all 
the principal components, which we saw in the summary table above.  Notice that 
the most important component (the one that explains most of the variation) is 
the one with the greatest SD.  Notice also that the magnitude of the SDs 
reflects the fact that we specified in the `prcomp()` call for the data to 
be scaled.

The `rotation` element is much more interesting:

```{r rotation}
m <- as.data.frame(format(pca$rotation, digits = 1))
knitr::kable(
  m, caption = '`rotation` matrix from `prcomp()`.'
)
```

Each column in the above table holds the components of a unit
vector^[Technically, an "eigenvector of the covariance matrix", as you can learn
from many online sources.  However, for greater numerical accuracy, `prcomp()`
uses singular value decomposition (SVD) to get the same result.] in the
direction of the "axis" corresponding to that principal component.

In a moment, we will anayze our PCA results using more rigorous methods, but 
at this point let's glean what we can from what we have inh front of us.  Note that 
these vectors are *in the frame of the original axes* (the features in our 
dataset.)  So, taking PC2 for example, we see that the **gear** component 
is much larger, relatively speaking, than the **cyl** component (0.551 vs 0.016); 
this means that the direction of PC2 is more "aligned with" the original 
"gear" feature axis than the "cyl" axis.  To put this another way, in terms 
of PC2, the value of the "gear" feature make more difference than the value of 
the "cyl" feature.

Now, suppose, for example, we had found a PCA direction that was almost 
completely aligned with one of the original feature axes, say, **disp**.  In 
other words, its **disp** component was close to 1 and all the others were 
close to zero.  This would mean that the "disp" feature by itself is somehow 
"important" in the data.  However, if the hypothetical PCA direction we are 
talking about here did not account for much of the overall variation in the 
data, then this finding might not be of much practical use.

```{r pc_heatmap, fig.margin = TRUE, fig.cap = "Overall importance of original features in the dataset, according to PCA.", fig.width=3.5, fig.height=3.5, cache=TRUE, message=FALSE, echo=FALSE}

# make a df of the PCA vector components weighted by Proportion of Variance
comps <- pca$rotation
comp_wts <- matrix(rep(summary(pca)$importance[2,], 9), nrow = 9, byrow = TRUE)
df <- data.frame(comps * comp_wts)

# tidy the df to make it compatible with ggplot
df <- cbind(rownames(df), data.frame(df, row.names = NULL))
colnames(df)[1] <- "attr"
df2 <- gather(df, colnames(df)[2:10], key = "PC", value = "comp")

# reorder the y-axis to match the table of vector components
# !!! must create new factor! cannot just change levels!
df2$attr <- factor(df2$attr, levels=(rev(rownames(m))))

# make the heatmap
ggplot(df2, aes(x = PC, y = attr)) + 
  geom_tile(aes(fill = comp), colour = "white") +
  guides(fill = "none") +
  scale_fill_gradient2(low = "darkblue", mid = "white", high = "darkred")
```


The plot at the right visually combines the information in the previous two 
tables.  In each column in the plot, bolder colors indicate larger components 
along the original feature axes (blue and red distinguish the sign of the 
component, but here only the magnitude matters.)  Then, the colors in each 
columnn are scaled by the "Proportion of Variance" in the PCA Summary table.  So 
we can tell at a glance that only the first 2 or 3 PCA directions are meaningful, 
and within those we can see which original features matter most.

We see that most of the correlation (interaction) in the data is among the 
features that have to do with how powerful a car's engine is, how much it weighs, 
and its fuel efficiency, and this probably "feels correct" for most of us. 
Remember, we are not talking about causality here; we are just looking at how 
the features we have included in the study interact to give rise to meaningful 
information in the data.

# More data returned by `prcomp()`: `center`, `scale`, `x`

We still haven't discussed the remaining three elements of the data 
structure returned by `prcomp()`.  The elements `center` and `scale` are both 
numeric vectors with the same number of elements there are features in the 
data that was passed to `prcomp()`.  Recall that we instructed `prcomp()` to 
center and scale the data; these vectors contain the numbers that were used 
to do that, for each feature.  Using these vectors, we can scale the data 
ourselves to see the numbers that `prcomp()` actually used for the analysis:

```{r old_scaled_data}
scaled_data <- scale(data, 
  center = pca$center, scale = pca$scale)
knitr::kable(
  format(scaled_data[1:6,], digits = 1), 
  caption = 'The centered and scaled data.'
)
```

The table above contains the same sample as the table at the beginning of 
this document, but with the numbers transformed in such as way as to put them 
all on the same footing in terms of magnitude and variance, which makes the 
analysis more accurate.  Please note that transforming the data in this 
way preserves the patterns in it, even though the numeric values have 
changed.

Finally, the element `x` in the information returned by `prcomp()` contains the 
*transformwd* data.  Recall that the purpose of PCA is to find a new set of 
axes that align with patterns in the data; when we do this, the vector of 
values that represents a sample does not really change its identity relative 
to all the other samples, but the numbers needed to define it in terms of 
the new axes are different.  The table below shows the transformed data for the 
same sample as above, and you can see that the numbers are different.

```{r old_xformed_data}
knitr::kable(
  format(pca$x[1:6,], digits = 1), 
  caption = 'The data transformed to the new PCA axes.'
)
```

# Data Transformation Illustration

Since we have all the above information at our fingertips, we might 
as well demonstrate how the vector of values for a sample is tranformed 
from one set of axes to another.^[You can learn about this application of 
matrix-vector multiplication from many online sources.] By multiplying the 
first row of centered and scaled values (Mazda RX4) by the rotation matrix 
(transposing as appropriate,) we produce a new vector that matches the first 
row in the transformed data, and by this we confirm that we understand the 
all the information returned by `prcomp()`.

```{r xform_check}
v_old <- scaled_data[1,]
A <- t(pca$rotation)
v_new <- A %*% v_old

knitr::kable(
  format(t(v_new), digits = 1), 
  caption = "Transformed data for Mazda RX4"
)
```

# Biplots

It is difficult to plot higher-dimensional data; however, given that 
our first two principal components capture 86% of the variation in our data, 
it might be worth making a 2-D scatterplot using just these two dimensions, 
to see if we can get any additional insight.

```{r my_biplot, fig.width = 5, fig.height = 5, echo = FALSE}
xformed_data <- as.data.frame(pca$x)
ggplot(xformed_data) +
  geom_point(aes(PC1, PC2), color = "blue") +
  geom_spoke(aes(x = 0, y = 0, angle = pi/6, radius = 1), color = "red") +
  xlim(-4, 4) + ylim(-4, 4)
```


```{r biplot, echo = FALSE, fig.width = 5, fig.height = 5, fig.fullwidth = TRUE}
ggbiplot(pca)
```

# (original document)

The Tufte handout style is a style that Edward Tufte uses in his books and handouts. Tufte's style is known for its extensive use of sidenotes, tight integration of graphics with text, and well-set typography. This style has been implemented in LaTeX and HTML/CSS^[See Github repositories [tufte-latex](https://github.com/tufte-latex/tufte-latex) and [tufte-css](https://github.com/edwardtufte/tufte-css)], respectively. We have ported both implementations into the [**tufte** package](https://github.com/rstudio/tufte). If you want LaTeX/PDF output, you may use the `tufte_handout` format for handouts, and `tufte_book` for books. For HTML output, use `tufte_html`. These formats can be either specified in the YAML metadata at the beginning of an R Markdown document (see an example below), or passed to the `rmarkdown::render()` function. See @R-rmarkdown for more information about **rmarkdown**.

```yaml
---
title: "An Example Using the Tufte Style"
author: "John Smith"
output:
  tufte::tufte_handout: default
  tufte::tufte_html: default
---
```

There are two goals of this package:

1. To produce both PDF and HTML output with similar styles from the same R Markdown document;
1. To provide simple syntax to write elements of the Tufte style such as side notes and margin figures, e.g. when you want a margin figure, all you need to do is the chunk option `fig.margin = TRUE`, and we will take care of the details for you, so you never need to think about `\begin{marginfigure} \end{marginfigure}` or `<span class="marginfigure"> </span>`; the LaTeX and HTML code under the hood may be complicated, but you never need to learn or write such code.

If you have any feature requests or find bugs in **tufte**, please do not hesitate to file them to https://github.com/rstudio/tufte/issues. For general questions, you may ask them on StackOverflow: http://stackoverflow.com/tags/rmarkdown.

# Headings

This style provides first and second-level headings (that is, `#` and `##`), demonstrated in the next section. You may get unexpected output if you try to use `###` and smaller headings.

`r newthought('In his later books')`^[[Beautiful Evidence](http://www.edwardtufte.com/tufte/books_be)], Tufte starts each section with a bit of vertical space, a non-indented paragraph, and sets the first few words of the sentence in small caps. To accomplish this using this style, call the `newthought()` function in **tufte** in an _inline R expression_ `` `r ` `` as demonstrated at the beginning of this paragraph.^[Note you should not assume **tufte** has been attached to your R session. You should either `library(tufte)` in your R Markdown document before you call `newthought()`, or use `tufte::newthought()`.]

# Figures

## Margin Figures

Images and graphics play an integral role in Tufte's work. To place figures in the margin you can use the **knitr** chunk option `fig.margin = TRUE`. For example:

```{r fig-margin, fig.margin = TRUE, fig.cap = "MPG vs horsepower, colored by transmission.", fig.width=3.5, fig.height=3.5, cache=TRUE, message=FALSE}
library(ggplot2)
mtcars2 <- mtcars
mtcars2$am <- factor(
  mtcars$am, labels = c('automatic', 'manual')
)
ggplot(mtcars2, aes(hp, mpg, color = am)) +
  geom_point() + geom_smooth() +
  theme(legend.position = 'bottom')
```

Note the use of the `fig.cap` chunk option to provide a figure caption. You can adjust the proportions of figures using the `fig.width` and `fig.height` chunk options. These are specified in inches, and will be automatically scaled down to fit within the handout margin.

## Arbitrary Margin Content

In fact, you can include anything in the margin using the **knitr** engine named `marginfigure`. Unlike R code chunks ```` ```{r} ````, you write a chunk starting with ```` ```{marginfigure} ```` instead, then put the content in the chunk. See an example on the right about the first fundamental theorem of calculus.

```{marginfigure}
We know from _the first fundamental theorem of calculus_ that for $x$ in $[a, b]$:
$$\frac{d}{dx}\left( \int_{a}^{x} f(u)\,du\right)=f(x).$$
```

For the sake of portability between LaTeX and HTML, you should keep the margin content as simple as possible (syntax-wise) in the `marginefigure` blocks. You may use simple Markdown syntax like `**bold**` and `_italic_` text, but please refrain from using footnotes, citations, or block-level elements (e.g. blockquotes and lists) there.

Note: if you set `echo = FALSE` in your global chunk options, you will have to add `echo = TRUE` to the chunk to display a margin figure, for example ```` ```{marginfigure, echo = TRUE} ````.

## Full Width Figures

You can arrange for figures to span across the entire page by using the chunk option `fig.fullwidth = TRUE`.

```{r fig-fullwidth, fig.width = 10, fig.height = 2, fig.fullwidth = TRUE, fig.cap = "A full width figure.", warning=FALSE, message=FALSE, cache=TRUE}
ggplot(diamonds, aes(carat, price)) + geom_smooth() +
  facet_grid(~ cut)
```

 Other chunk options related to figures can still be used, such as `fig.width`, `fig.cap`, `out.width`, and so on. For full width figures, usually `fig.width` is large and `fig.height` is small. In the above example, the plot size is $10 \times 2$.

## Main Column Figures

Besides margin and full width figures, you can of course also include figures constrained to the main column. This is the default type of figures in the LaTeX/HTML output.

```{r fig-main, fig.cap = "A figure in the main column.", cache=TRUE}
ggplot(diamonds, aes(cut, price)) + geom_boxplot()
```

# Sidenotes

One of the most prominent and distinctive features of this style is the extensive use of sidenotes. There is a wide margin to provide ample room for sidenotes and small figures. Any use of a footnote will automatically be converted to a sidenote. ^[This is a sidenote that was entered using a footnote.] 

If you'd like to place ancillary information in the margin without the sidenote mark (the superscript number), you can use the `margin_note()` function from **tufte** in an inline R expression. `r margin_note("This is a margin note.  Notice that there is no number preceding the note.")` This function does not process the text with Pandoc, so Markdown syntax will not work here. If you need to write anything in Markdown syntax, please use the `marginfigure` block described previously.

# References

References can be displayed as margin notes for HTML output. For example, we can cite R here [@R-base]. To enable this feature, you must set `link-citations: yes` in the YAML metadata, and the version of `pandoc-citeproc` should be at least 0.7.2. You can always install your own version of Pandoc from http://pandoc.org/installing.html if the version is not sufficient. To check the version of `pandoc-citeproc` in your system, you may run this in R:

```{r eval=FALSE}
system2('pandoc-citeproc', '--version')
```

If your version of `pandoc-citeproc` is too low, or you did not set `link-citations: yes` in YAML, references in the HTML output will be placed at the end of the output document.

# Tables

You can use the `kable()` function from the **knitr** package to format tables that integrate well with the rest of the Tufte handout style. The table captions are placed in the margin like figures in the HTML output.

```{r}
knitr::kable(
  mtcars[1:6, 1:6], caption = 'A subset of mtcars.'
)
```

# Block Quotes

We know from the Markdown syntax that paragraphs that start with `>` are converted to block quotes. If you want to add a right-aligned footer for the quote, you may use the function `quote_footer()` from **tufte** in an inline R expression. Here is an example:

> "If it weren't for my lawyer, I'd still be in prison. It went a lot faster with two people digging."
>
> `r tufte::quote_footer('--- Joe Martin')`

Without using `quote_footer()`, it looks like this (the second line is just a normal paragraph):

> "Great people talk about ideas, average people talk about things, and small people talk about wine."
>
> --- Fran Lebowitz

# Responsiveness

The HTML page is responsive in the sense that when the page width is smaller than 760px, sidenotes and margin notes will be hidden by default. For sidenotes, you can click their numbers (the superscripts) to toggle their visibility. For margin notes, you may click the circled plus signs to toggle visibility.

# More Examples

The rest of this document consists of a few test cases to make sure everything still works well in slightly more complicated scenarios. First we generate two plots in one figure environment with the chunk option `fig.show = 'hold'`:

```{r fig-two-together, fig.cap="Two plots in one figure environment.", fig.show='hold', cache=TRUE, message=FALSE}
p <- ggplot(mtcars2, aes(hp, mpg, color = am)) +
  geom_point()
p
p + geom_smooth()
```

Then two plots in separate figure environments (the code is identical to the previous code chunk, but the chunk option is the default `fig.show = 'asis'` now):

```{r fig-two-separate, ref.label='fig-two-together', fig.cap=sprintf("Two plots in separate figure environments (the %s plot).", c("first", "second")), cache=TRUE, message=FALSE}
```

You may have noticed that the two figures have different captions, and that is because we used a character vector of length 2 for the chunk option `fig.cap` (something like `fig.cap = c('first plot', 'second plot')`).

Next we show multiple plots in margin figures. Similarly, two plots in the same figure environment in the margin:

```{r fig-margin-together, fig.margin=TRUE, fig.show='hold', fig.cap="Two plots in one figure environment in the margin.", fig.width=3.5, fig.height=2.5, cache=TRUE}
p
p + geom_smooth(method = 'lm')
```

Then two plots from the same code chunk placed in different figure environments:

```{r fig-margin-separate, fig.margin=TRUE, fig.cap=sprintf("Two plots in separate figure environments in the margin (the %s plot).", c("first", "second")), fig.width=3.5, fig.height=2.5, cache=TRUE}
knitr::kable(head(iris, 15))
p
knitr::kable(head(iris, 12))
p + geom_smooth(method = 'lm')
knitr::kable(head(iris, 5))
```

We blended some tables in the above code chunk only as _placeholders_ to make sure there is enough vertical space among the margin figures, otherwise they will be stacked tightly together. For a practical document, you should not insert too many margin figures consecutively and make the margin crowded. 

You do not have to assign captions to figures. We show three figures with no captions below in the margin, in the main column, and in full width, respectively.

```{r fig-nocap-margin, fig.margin=TRUE, fig.width=3.5, fig.height=2, cache=TRUE}
# a boxplot of weight vs transmission; this figure
# will be placed in the margin
ggplot(mtcars2, aes(am, wt)) + geom_boxplot() +
  coord_flip()
```
```{r fig-nocap-main, cache=TRUE}
# a figure in the main column
p <- ggplot(mtcars, aes(wt, hp)) + geom_point()
p
```
```{r fig-nocap-fullwidth, fig.fullwidth=TRUE, fig.width=10, fig.height=3, cache=TRUE}
# a fullwidth figure
p + geom_smooth(method = 'lm') + facet_grid(~ gear)
```

# Some Notes on Tufte CSS

There are a few other things in Tufte CSS that we have not mentioned so far. If you prefer `r sans_serif('sans-serif fonts')`, use the function `sans_serif()` in **tufte**. For epigraphs, you may use a pair of underscores to make the paragraph italic in a block quote, e.g.

> _I can win an argument on any topic, against any opponent. People know this, and steer clear of me at parties. Often, as a sign of their great respect, they don't even invite me._
>
> `r quote_footer('--- Dave Barry')`

We hope you will enjoy the simplicity of R Markdown and this R package, and we sincerely thank the authors of the Tufte-CSS and Tufte-LaTeX projects for developing the beautiful CSS and LaTeX classes. Our **tufte** package would not have been possible without their heavy lifting.

You can turn on/off some features of the Tufte style in HTML output. The default features enabled are:

```yaml
output:
  tufte::tufte_html:
    tufte_features: ["fonts", "background", "italics"]
```

If you do not want the page background to be lightyellow, you can remove `background` from `tufte_features`. You can also customize the style of the HTML page via a CSS file. For example, if you do not want the subtitle to be italic, you can define

```css
h3.subtitle em {
  font-style: normal;
}
```

in, say, a CSS file `my_style.css` (under the same directory of your Rmd document), and apply it to your HTML output via the `css` option, e.g.,

```yaml
output:
  tufte::tufte_html:
    tufte_features: ["fonts", "background"]
    css: "my_style.css"
```

There is also a variant of the Tufte style in HTML/CSS named "[Envisoned CSS](http://nogginfuel.com/envisioned-css/)". This style can be used by specifying the argument `tufte_variant = 'envisioned'` in `tufte_html()`^[The actual Envisioned CSS was not used in the **tufte** package. We only changed the fonts, background color, and text color based on the default Tufte style.], e.g.

```yaml
output:
  tufte::tufte_html:
    tufte_variant: "envisioned"
```

To see the R Markdown source of this example document, you may follow [this link to Github](https://github.com/rstudio/tufte/raw/master/inst/rmarkdown/templates/tufte_html/skeleton/skeleton.Rmd), use the wizard in RStudio IDE (`File -> New File -> R Markdown -> From Template`), or open the Rmd file in the package:

```{r eval=FALSE}
file.edit(
  tufte:::template_resources(
    'tufte_html', '..', 'skeleton', 'skeleton.Rmd'
  )
)
```

This document is also available in [Chinese](http://rstudio.github.io/tufte/cn/), and its `envisioned` style can be found [here](http://rstudio.github.io/tufte/envisioned/).

```{r bib, include=FALSE}
# create a bib file for the R packages used in this document
knitr::write_bib(c('base', 'rmarkdown'), file = 'skeleton.bib')
```
